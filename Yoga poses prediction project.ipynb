{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd800b2",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\" font-size=30>Deep learning project</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655bd6d",
   "metadata": {},
   "source": [
    "#### group : Mariem mazouz / safa chaari / abir barouni /ghofrane soltani / med aziz omrani / aziz tebessi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce90ba",
   "metadata": {},
   "source": [
    "### importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn.utils import shuffle           \n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925cf25",
   "metadata": {},
   "source": [
    "### Data understanding and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709f5506",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"C:/Users/Abir/Desktop/4DS/lab_4ds_yoga/YOGA/content/cleaned/DATASET/TRAIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_example_dir = train_path + r'/tree/00000071.jpg'\n",
    "tree_example_img = imread(tree_example_dir)\n",
    "tree_example_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of images\n",
    "category = []\n",
    "number_images = []\n",
    "for cat in os.listdir(train_path):\n",
    "    print(\"Number of \" + cat + \" images : \" + str(len(os.listdir(train_path+'/'+cat))))\n",
    "    category.append(cat)\n",
    "    number_images.append(len(os.listdir(train_path+'/'+cat)))    \n",
    "print(\"Total Number of Images : \" + str(np.sum(number_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad036068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing with pie chart\n",
    "plt.pie(number_images, labels = category, autopct='%.0f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7aea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['downdog', 'goddess', 'plank', 'tree', 'warrior2']\n",
    "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "IMAGE_SIZE = (200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc40b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "   \n",
    "    datasets = [r'C:/Users/Abir/Desktop/4DS/lab_4ds_yoga/YOGA/content/cleaned/DATASET/TRAIN', r'C:/Users/Abir/Desktop/4DS/lab_4ds_yoga/YOGA/content/cleaned/DATASET/Test']\n",
    "    output = []\n",
    "    \n",
    "    # Iterate through the training and test set.\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        images = [] \n",
    "        labels = []\n",
    "        \n",
    "        print(\"Loading {}\".format(dataset))\n",
    "        \n",
    "        # Iterate through each Subfolder corresponding to a category  \n",
    "        for folder in os.listdir(dataset):\n",
    "            label = class_names_label[folder]\n",
    "            \n",
    "            # Iterate through each image in our folder\n",
    "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
    "                \n",
    "                # Image path should be obtained\n",
    "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
    "                \n",
    "                # Open and resize the img\n",
    "                image = cv.imread(img_path)\n",
    "                image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "                image = cv.resize(image, IMAGE_SIZE) \n",
    "                \n",
    "                # Append the image along with its label to the output\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "                \n",
    "        images = np.array(images, dtype = 'float32')\n",
    "        labels = np.array(labels, dtype = 'int32')\n",
    "        \n",
    "        # Shuffle the images to introduce some randomness in our data\n",
    "        images, labels = shuffle(images, labels)\n",
    "        \n",
    "        \n",
    "        output.append((images, labels))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39033eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_counts = np.unique(train_labels, return_counts=True)\n",
    "_, test_counts = np.unique(test_labels, return_counts=True)\n",
    "pd.DataFrame({'train': train_counts,'test': test_counts}, index=class_names).plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96b4652",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b86eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeCorruptedImages(path):\n",
    "    for filename in os.listdir(path):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(path,filename))\n",
    "            img.verify() \n",
    "        except (IOError, SyntaxError) as e:\n",
    "            print('Bad file:', filename)\n",
    "            os.remove(os.path.join(path,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2a6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for any corrupted images and delete them\n",
    "# code obtained from https://stackoverflow.com/questions/67505710/pil-unidentifiedimageerror-cannot-identify-image-file-io-bytesio-object\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "from PIL import UnidentifiedImageError\n",
    "\n",
    "path = Path(train_path).rglob(\"*.jpg\")\n",
    "for img_p in path:\n",
    "    try:\n",
    "        img = PIL.Image.open(img_p)\n",
    "    except PIL.UnidentifiedImageError:\n",
    "        print(img_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cea8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore the average dimension of the images\n",
    "error_image = []\n",
    "for cat in os.listdir(train_path):\n",
    "    dim1 = []\n",
    "    dim2 = []\n",
    "    for image_filename in os.listdir(train_path+'/'+cat+'/'):    \n",
    "        try:\n",
    "            img = imread(train_path+'/'+cat+'/'+image_filename)\n",
    "        except:\n",
    "            print(\"Error reading file on \" + cat + \" %s\" %image_filename)\n",
    "            error_image.append(train_path +'/'+ cat + '/' + image_filename)\n",
    "            continue\n",
    "        if len(img.shape)==2: #Reshape some images with single color channel\n",
    "            img = img.reshape(img.shape[0],img.shape[1],1)\n",
    "        if len(img.shape)==0:\n",
    "            print(\"Image shape = 0 on \" + cat + \" %s\" %image_filename)\n",
    "            error_image.append(train_path + '/'+cat + '/' + image_filename)\n",
    "        else:\n",
    "            d1,d2,colors = img.shape\n",
    "            dim1.append(d1)\n",
    "            dim2.append(d2)\n",
    "    p = sns.jointplot(dim1,dim2)\n",
    "    p.fig.suptitle(\"Dimensions of %s images\" %cat)\n",
    "    print(\"Mean of dim1 on \" + cat + \" is \"+ str(np.mean(dim1)))\n",
    "    print(\"Mean of dim2 on \" + cat + \" is \"+ str(np.mean(dim2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db71839",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2d5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll remove all files that show problem and resize the image to 600 x 600 pixels in image generating process.\n",
    "for file in error_image:\n",
    "    os.remove(file)\n",
    "print(\"Completed removing the files that have problems...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c2af0",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e573f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'C:/Users/Abir/Desktop/4DS/lab_4ds_yoga/YOGA/content/cleaned/DATASET/TRAIN'\n",
    "test_path = r'C:/Users/Abir/Desktop/4DS/lab_4ds_yoga/YOGA/content/cleaned/DATASET/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_images(dataset_path):\n",
    "    images_data = []\n",
    "    images_label = []\n",
    "    class_names = os.listdir(dataset_path)\n",
    "    for class_name in class_names:\n",
    "        images_path = dataset_path + '/' + class_name\n",
    "        images = os.listdir(images_path)\n",
    "        for image in images:\n",
    "            bgr_img = cv2.imread(images_path + '/' + image)\n",
    "            # dsize\n",
    "            dsize = (200,200)\n",
    "            #resize image\n",
    "            resized_image = cv2.resize(bgr_img,dsize)\n",
    "            # convert from BGR color-space to YCrCb for the luminosity correction to red and blue\n",
    "            ycrcb_img = cv2.cvtColor(resized_image, cv2.COLOR_BGR2YCrCb)\n",
    "            # create a CLAHE object \n",
    "            clahe = cv2.createCLAHE(clipLimit=25.0, tileGridSize=(20,20))\n",
    "            # Now apply CLAHE object on the YCrCb image\n",
    "            ycrcb_img[:, :, 0] = clahe.apply(ycrcb_img[:, :, 0])\n",
    "            # convert back to BGR color-space from YCrCb\n",
    "            equalized_img = cv2.cvtColor(ycrcb_img, cv2.COLOR_YCrCb2BGR)\n",
    "            # Denoise is done to remove unwanted noise to better perform\n",
    "            equalized_denoised_image = cv2.fastNlMeansDenoisingColored(equalized_img, 10, 10, 10, 7, 21)\n",
    "\n",
    "            images_data.append(equalized_denoised_image/255)\n",
    "            images_label.append(class_name)\n",
    "    #pour pouvoir les utiliser dans des opérations mathématiques et de traitement d'image ultérieures plus facilement et efficacement.\n",
    "    images_data = np.array(images_data)\n",
    "    images_label = np.array(images_label)\n",
    "    return images_data, images_label\n",
    "\n",
    "def visualize(original, augmented):\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Augmented image')\n",
    "    plt.imshow(original)\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Augmented image')\n",
    "    plt.imshow(augmented)\n",
    "    plt.show()\n",
    "\n",
    "train_images_data, train_images_label = preprocess_images(train_path)\n",
    "\n",
    "# Visualize the first image in the dataset\n",
    "visualize(train_images_data[10], train_images_data[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f77dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_targets(labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    images_label = le.fit_transform(labels)\n",
    "    return images_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "class_names = os.listdir(train_path)\n",
    "class_num = len(class_names)\n",
    "train_images_label = encoding_targets(train_images_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfdba80",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation is the process of transforming images to create new ones, for training models.\n",
    "# Data augmentation increases the number of examples in the training set while also introducing more variety \n",
    "#in what the model sees and learns from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc102eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory with its sub folders\n",
    "from os import walk\n",
    "for (dirpath, dirnames, filenames) in walk(r'C:/Users/Abir/Desktop/4DS/lab_4ds_yoga/YOGA/content/cleaned/DATASET'):\n",
    "    print(\"Directory path: \", dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009dac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(original, augmented):\n",
    "  fig = plt.figure()\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.title('Original image')\n",
    "  plt.imshow(original)\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.title('Augmented image')\n",
    "  plt.imshow(augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8572f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Create an empty list to store the image filenames\n",
    "image_files = []\n",
    "\n",
    "for file in os.listdir(dirpath):\n",
    "    # Check if the file has a valid image extension\n",
    "    if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
    "        # Add the file name to the list of image files\n",
    "        image_files.append(os.path.join(dirpath, file))\n",
    "\n",
    "# Print the list of image filenames\n",
    "print(image_files)\n",
    "\n",
    "# visualization: \n",
    "# Loop through each image file and display it\n",
    "for image_file in image_files:\n",
    "    # Load the image using matplotlib\n",
    "    image = mpimg.imread(image_file)\n",
    "\n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ff643b",
   "metadata": {},
   "source": [
    "ROTATING THE IMAGE:\n",
    "\n",
    "One of the most commonly used augmentation techniques is image rotation.\n",
    "Even if we rotate the image, the information on the image remains the same.\n",
    "Otherwise, A yoga pose is yogaa pose, even if we see it from a different angle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b6029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rotate\n",
    "#Rotating the image to 90 degree angle\n",
    "rotated_image = tf.image.rot90(image)\n",
    "visualize(image, rotated_image)\n",
    "\n",
    "#Rotating the image to 180 degree angle\n",
    "rotated = rotate(image, angle=180, mode = 'wrap')\n",
    "visualize(image, rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa373ae3",
   "metadata": {},
   "source": [
    "APPLYING THE GRAYSCALE FEATURES TO THE IMAGE:\n",
    "\n",
    "Grayscale augmentation randomly causes an input image to be converted to a single channel, grayscale output image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968096dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscaled_image = tf.image.rgb_to_grayscale(image)\n",
    "visualize(image, tf.squeeze(grayscaled_image))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271b824",
   "metadata": {},
   "source": [
    "### Modeling phase with preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(200, 200, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac81d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506224db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20291e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images_data, train_images_label, batch_size = 28, epochs=5, validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cdedf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history):\n",
    "\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"Training_accuracy vs Validation_accuracy\")\n",
    "    plt.ylabel(\"ACCURACY\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss_function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"Training_loss vs Validation_loss\")\n",
    "    plt.ylabel(\"LOSS\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(train_images_data, train_images_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965bc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, the index is into the flattened array, otherwise along the specified axis.\n",
    "predictions = model.predict(train_images_data)\n",
    "pred_labels = np.argmax(predictions,axis=1)  # np.argmax is used since each prediction would be an array of...\n",
    "                                             # probabilities and we need to pick the max value. \n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f65a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5, figsize = (15,15))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(0,25):  \n",
    "    ax[i].imshow(train_images_data[i])\n",
    "    ax[i].set_title(f\"predicted class: {class_names[pred_labels[i]]} \\n Actual Class: {class_names[train_images_label[i]]}\")\n",
    "    ax[i].axis('off')\n",
    "plt.subplots_adjust(wspace=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02a75c",
   "metadata": {},
   "source": [
    "## Modeling phase without preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a28d3f8",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll start by viewing an example of the data and normalizing between [0,1]the values since they are in the range of [0,255]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba83ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "model_l2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(200, 200)),\n",
    "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu',kernel_regularizer=regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b94218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_l2 = Sequential()\n",
    "model_l2.add(Conv2D(32, (3, 3), input_shape=(200, 200, 3)))\n",
    "model_l2.add(Activation('relu'))\n",
    "model_l2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_l2.add(Conv2D(64, (3, 3)))\n",
    "model_l2.add(Activation('relu'))\n",
    "model_l2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_l2.add(Conv2D(128, (3, 3)))\n",
    "model_l2.add(Activation('relu'))\n",
    "model_l2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model_l2.add(Conv2D(128, (3, 3)))\n",
    "model_l2.add(Activation('relu'))\n",
    "model_l2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model_l2.add(Flatten())\n",
    "model_l2.add(Dense(64))\n",
    "model_l2.add(Activation('relu'))\n",
    "model_l2.add(Dropout(0.5))\n",
    "model_l2.add(Dense(5))\n",
    "model_l2.add(Activation('softmax'))\n",
    "model_l2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imread\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#import shap\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import tensorflow.keras.layers as tfl\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "\n",
    "#defines the rate of which an algo converges to a solution\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "# compile the model with the optimizer instance\n",
    "model_l2.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# we couldn't change the loss function because  the difference between the two is that categorical_crossentropy requires the true class labels to be one-hot encoded, whereas sparse_categorical_crossentropy does not. Instead, sparse_categorical_crossentropy can handle integer class labels directly, making it a more memory-efficient option for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2473417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5, shuffle=True,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe71fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define per-fold score containers\n",
    "val_acc_per_fold = []\n",
    "val_loss_per_fold = []\n",
    "loss_per_fold = []\n",
    "acc_per_fold = []\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, valid in kfold.split(train_images,train_labels):\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model_l2.fit(train_images[train], train_labels[train], batch_size=16, \n",
    "                        epochs=epochs, validation_data=(train_images[valid], train_labels[valid]))\n",
    "    val_acc_per_fold.append(history.history['val_accuracy'])\n",
    "    acc_per_fold.append(history.history['accuracy'])\n",
    "    val_loss_per_fold.append(history.history['val_loss'])\n",
    "    loss_per_fold.append(history.history['loss'])\n",
    "    # Increase fold number\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097dd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model_l2.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history):\n",
    "\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"Training_accuracy vs Validation_accuracy\")\n",
    "    plt.ylabel(\"ACCURACY\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss_function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"Training_loss vs Validation_loss\")\n",
    "    plt.ylabel(\"LOSS\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, the index is into the flattened array, otherwise along the specified axis.\n",
    "predictions = model_l2.predict(test_images)\n",
    "pred_labels = np.argmax(predictions,axis=1)  # np.argmax is used since each prediction would be an array of...\n",
    "                                             # probabilities and we need to pick the max value. \n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ecd39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5, figsize = (15,15))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(0,25):  \n",
    "    ax[i].imshow(test_images[i])\n",
    "    ax[i].set_title(f\"predicted class: {class_names[pred_labels[i]]} \\n Actual Class: {class_names[test_labels[i]]}\")\n",
    "    ax[i].axis('off')\n",
    "plt.subplots_adjust(wspace=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fee6d1",
   "metadata": {},
   "source": [
    "### model 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80c2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tf.keras.Sequential([\n",
    "        tfl.Conv2D(filters=16, kernel_size=(3,3), activation='relu',input_shape=(200,200,3)),\n",
    "        tfl.MaxPool2D(pool_size=(2,2)),\n",
    "        tfl.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
    "        tfl.BatchNormalization(axis=-1),\n",
    "        tfl.Dropout(rate=0.25),\n",
    "        \n",
    "    \n",
    "        tfl.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "        tfl.MaxPool2D(pool_size=(2,2)),\n",
    "        tfl.BatchNormalization(axis=-1),\n",
    "        tfl.Dropout(rate=0.25),    \n",
    "        \n",
    "    \n",
    "        tfl.Flatten(),\n",
    "        tfl.Dense(512,activation='relu'),\n",
    "        tfl.BatchNormalization(),\n",
    "        tfl.Dropout(rate=0.5),\n",
    "    \n",
    "        tfl.Dense(class_num, activation='softmax')\n",
    "        \n",
    "])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eabe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An epoch is when all the training data is used at once and is defined as the total number of iterations of all the training\n",
    "#data in one cycle for training the machine learning model.\n",
    "epochs = 5\n",
    "#defines the rate of which an algo converges to a solution\n",
    "learning_rate = 0.001\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "# compile the model with the optimizer instance\n",
    "model3.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# we couldn't change the loss function because  the difference between the two is that categorical_crossentropy requires the true class labels to be one-hot encoded, whereas sparse_categorical_crossentropy does not. Instead, sparse_categorical_crossentropy can handle integer class labels directly, making it a more memory-efficient option for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d17349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5, shuffle=True,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "# Define per-fold score containers\n",
    "val_acc_per_fold = []\n",
    "val_loss_per_fold = []\n",
    "loss_per_fold = []\n",
    "acc_per_fold = []\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, valid in kfold.split(train_images_data, train_images_label):\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    history = model3.fit(train_images_data[train], train_images_label[train], batch_size=16, \n",
    "                        epochs=epochs, validation_data=(train_images_data[valid], train_images_label[valid]),callbacks=[early_stop])\n",
    "    val_acc_per_fold.append(history.history['val_accuracy'])\n",
    "    acc_per_fold.append(history.history['accuracy'])\n",
    "    val_loss_per_fold.append(history.history['val_loss'])\n",
    "    loss_per_fold.append(history.history['loss'])\n",
    "    # Increase fold number\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of metrics per fold\n",
    "mean_acc_per_fold = [np.mean(scores) * 100 for scores in acc_per_fold]\n",
    "std_acc_per_fold = [np.std(scores) for scores in acc_per_fold]\n",
    "\n",
    "mean_val_acc_per_fold = [np.mean(scores) * 100 for scores in val_acc_per_fold]\n",
    "std_val_acc_per_fold = [np.std(scores) for scores in val_acc_per_fold]\n",
    "\n",
    "mean_loss_per_fold = [np.mean(scores) for scores in loss_per_fold]\n",
    "std_loss_per_fold = [np.std(scores) for scores in loss_per_fold]\n",
    "\n",
    "mean_val_loss_per_fold = [np.mean(scores) for scores in val_loss_per_fold]\n",
    "std_val_loss_per_fold = [np.std(scores) for scores in val_loss_per_fold]\n",
    "\n",
    "# Print results\n",
    "for i in range(0, len(mean_acc_per_fold)):\n",
    "    print(f'> Fold {i+1} - Training Accuracy: {mean_acc_per_fold[i]:.2f}% (+- {std_acc_per_fold[i]:.2f})')\n",
    "    print(f'> Fold {i+1} - Validation Accuracy: {mean_val_acc_per_fold[i]:.2f}% (+- {std_val_acc_per_fold[i]:.2f})')\n",
    "    print(f'> Fold {i+1} - Training Loss: {mean_loss_per_fold[i]:.4f} (+- {std_loss_per_fold[i]:.4f})')\n",
    "    print(f'> Fold {i+1} - Validation Loss: {mean_val_loss_per_fold[i]:.4f} (+- {std_val_loss_per_fold[i]:.4f})')\n",
    "\n",
    "# Print mean and standard deviation of metrics across all folds\n",
    "print(f'> Mean Training Accuracy: {np.mean(mean_acc_per_fold):.2f}% (+- {np.mean(std_acc_per_fold):.2f})')\n",
    "print(f'> Mean Validation Accuracy: {np.mean(mean_val_acc_per_fold):.2f}% (+- {np.mean(std_val_acc_per_fold):.2f})')\n",
    "print(f'> Mean Training Loss: {np.mean(mean_loss_per_fold):.4f} (+- {np.mean(std_loss_per_fold):.4f})')\n",
    "print(f'> Mean Validation Loss: {np.mean(mean_val_loss_per_fold):.4f} (+- {np.mean(std_val_loss_per_fold):.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc342f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model3.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history):\n",
    "\n",
    "    fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['accuracy'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_accuracy'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"Training_accuracy vs Validation_accuracy\")\n",
    "    plt.ylabel(\"ACCURACY\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss_function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"Training_loss vs Validation_loss\")\n",
    "    plt.ylabel(\"LOSS\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16298913",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd6684",
   "metadata": {},
   "source": [
    "### Model prediction : we focused on the second model based on its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e22d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model3.predict(test_images)\n",
    "pred_labels = np.argmax(predictions,axis=1)  # np.argmax is used since each prediction would be an array of...\n",
    "                                             # probabilities and we need to pick the max value. \n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d7a2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5, figsize = (15,15))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i in range(0,25):  \n",
    "    ax[i].imshow(test_images[i])\n",
    "    ax[i].set_title(f\"predicted class: {class_names[pred_labels[i]]} \\n Actual Class: {class_names[test_labels[i]]}\")\n",
    "    ax[i].axis('off')\n",
    "plt.subplots_adjust(wspace=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2e784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
